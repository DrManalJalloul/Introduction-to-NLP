{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 2: Practical Exercise – “From Raw Reviews to Batched Tensors”**"
      ],
      "metadata": {
        "id": "jJGWSmUFcQsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "\n",
        "In this notebook, you will create a reusable PyTorch data pipeline that reads 2 000 Amazon-review lines, cleans and tokenises each sentence (using your Week-1 code), converts them to integer ID sequences, pads them to equal length, and serves batches of tensors ready for an LSTM.\n",
        "You have been provided file amazon_2k.csv with columns text, label where label is 0 = negative, 1 = positive. Please make sure to upload it to this session's Files.\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "CsQc_HUxcdpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Environment check**"
      ],
      "metadata": {
        "id": "QVPF112sdcGx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egYqn_HecNf0"
      },
      "outputs": [],
      "source": [
        "import torch, platform, sys\n",
        "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Load data**"
      ],
      "metadata": {
        "id": "CUCpmrS6dlq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First download the [amazon_2k.csv](https://github.com/nlp-course-data/public-data/raw/main/amazon_2k.csv) and upload it to this session storage."
      ],
      "metadata": {
        "id": "z5e9JTPOh4UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"amazon_2k.csv\")\n",
        "texts  = df[\"text\"].tolist()\n",
        "labels = df[\"label\"].tolist()\n"
      ],
      "metadata": {
        "id": "NYRLLq_rdqMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Reuse cleaner & tokenizer from Week 1**"
      ],
      "metadata": {
        "id": "tJDAIA8wdtg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO : Write the functions for your tokenizer (my_tokenizer) and cleaner (clean_text) that you had completed in Week 1\n",
        "tokens = [my_tokeniser(clean_text(t)) for t in texts]"
      ],
      "metadata": {
        "id": "MUJTmHwFeDCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Build ReviewDataset**"
      ],
      "metadata": {
        "id": "V-9dRwpDeOY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "  #TODO : Write the ReviewDataset Class\n",
        "\n",
        "ds = ReviewDataset(tokens, labels)\n",
        ""
      ],
      "metadata": {
        "id": "AxHua3D7eS-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Write the collate_batch function**"
      ],
      "metadata": {
        "id": "Zxx6EUC5etox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "PAD_ID = 0\n",
        "def collate_batch(batch):\n",
        "    #TODO : Write teh collate_batch function"
      ],
      "metadata": {
        "id": "GWmk0Dn4ezpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Create DataLoader**"
      ],
      "metadata": {
        "id": "SJF1-2YRfUvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loader = DataLoader(ds, batch_size=32, shuffle=True, collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "stZ77Rb2fbH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Visual check**"
      ],
      "metadata": {
        "id": "w02scPpafdpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_ids, batch_mask, batch_lbl = next(iter(loader))\n",
        "print(\"IDs shape :\", batch_ids.shape)\n",
        "print(\"Mask shape:\", batch_mask.shape)\n",
        "print(\"First 2 ID rows:\\n\", batch_ids[:2])\n",
        "print(\"First 2 masks:\\n\", batch_mask[:2])\n"
      ],
      "metadata": {
        "id": "vHMPrcnZfjgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "\n",
        "Running this exercise successfully will give you a plug-and-play DataLoader you can feed directly into the LSTM training loop in Lesson 3."
      ],
      "metadata": {
        "id": "Wo0kkID5fl-b"
      }
    }
  ]
}